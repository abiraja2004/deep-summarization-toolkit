$schema: ../dst/schemas/modelrun.schema.json
# Model prefix, describes name folder with model dumps and logs
prefix: dev-ria-20-t-il
dataset:
  # Class name of used dataset stored in dst.data
  name: RIADataset
  # See class documentations for more details.
  args:
    # Initialization args, need for dataset instantiation.
    init:
      # Directory with raw dataset files, such as {train, test, dev}.tsv parts.
      directory: ./datasets/ria-20
      # Dataset prefix. All preprocessed data should stored with this prefix.
      prefix: ria-100-cbow
      # Whether to use dev part of dataset as train part.
      dev: True
      # Specific for RIA dataset.
      # Number of sentences from original news.
      n_sentences: 3
      # Specific for RIA dataset.
      # Whether to remove html tags from news.
      rm_strongs: True
      # Specific for RIA dataset.
      # The distribution of dataset part sizes.
      # -1 means remaining.
      parts:
        train: -1
        test: 20000
        dev: 5000
    preprocess:
      # Whether to pretrain word2vec embeddings.
      pretrain_emb: True
      # Vocabulary size.
      vocab_size: 10000
      # Embedding size.
      embedding_size: 100
      # Specific fro sentencepiece. Maximum text length on one line.
      max_sentence_length: 16384
      # Number of cpu workers.
      workers: 3
      # Whether to use skip-gram word2vec approach.
      skip_gramm: False

model:
  # Class name of used model stored int dst.models
  name: PBATransformer
  # See class documentation for more details.
  args:
    num_layers: 1
    emb_size: 100
    dim_m: 64
    dim_i: 64
    attention: interleaved

optimizer:
  # Class name of used optimizer stored in torch.optim
  name: Adam
  # You may pass `args` to use default arguments.

training:
  # Class name of used pipeline stored in dst.train.
  name: SummarizationPipeline
  epochs: 3
  device: cpu
  # Checkpoint and logging intervals.
  intervals:
    checkpoint: 100
    log: 100
  # Batch sizing.
  batches:
    train_size: 16
    eval_size: 32

evaluation:
  # Describe evaluation args, pass this config to use default arguments.
  args:
    beam_size: 1

sample:
  # Describe sampling args, pass this config to use default arguments.
  args:
    limit: 15
    beam_size: 1

model: PBATransformer
margs:
  num_layers: 6
  emb_size: 300
  dim_m: 512
  dim_i: 2048
  attention: interleaved

dataset: RIADataset
dargs:
  directory: ./datasets/ria
  prefix: ria-300
  max_sequence_length: 150

device: cuda
state_path: ./workbench/pba-transformer-il/model.pth
inference_args:
  limit: 42
  beam_size: 5
